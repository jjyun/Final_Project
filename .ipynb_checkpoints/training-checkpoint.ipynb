{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import dependencies\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pyimagesearch.smallervggnet import SmallerVGGNet\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define variables\n",
    "-  Set epochs\n",
    "-  Set learning rate\n",
    "-  Set batch size\n",
    "-  Create empty arrays to hold data matrix and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Set Epochs, learning rate and batch size\n",
    "EPOCHS = 20\n",
    "INIT_LR = 1e-3\n",
    "BS = 32\n",
    "\n",
    "#Create empty arrays to append the matrix information\n",
    "data = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Imutils to grab the image paths from the dataset directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the image paths and randomly shuffle them\n",
    "imagePaths = list(paths.list_images(\"dataset\"))\n",
    "random.seed(42)\n",
    "random.shuffle(imagePaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset\\corgi\\00000139.jpg\n",
      "dataset\\xoloitzcuintli\\00000030.jpg\n",
      "dataset\\xoloitzcuintli\\00000212.jpg\n",
      "dataset\\chihuahua\\00000190.jpg\n",
      "dataset\\xoloitzcuintli\\00000026.jpg\n",
      "dataset\\xoloitzcuintli\\00000205.jpg\n",
      "dataset\\corgi\\00000087.jpg\n",
      "dataset\\xoloitzcuintli\\00000153.jpg\n",
      "dataset\\chihuahua\\00000180.jpg\n"
     ]
    }
   ],
   "source": [
    "#Display first 10 imagePaths to check if shuffle and pathing is correct\n",
    "for i in range(0,9):\n",
    "    print(imagePaths[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate empty arrays\n",
    "\n",
    "### Data\n",
    "1. Iterate over all imagepaths\n",
    "2. Read in the image using OpenCV\n",
    "3. Resize image using OpenCV\n",
    "4. Fill Data array with image matrix\n",
    "\n",
    "### Labels\n",
    "1. Split the file path using os.path.sep _dataset\\chihuahua\\00000180.jpg_ into dataset \\ chihuahua \\ XXX.jpg\n",
    "2. Append the label to the empty label array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop over the input images\n",
    "for imagePath in imagePaths:\n",
    "\timage = cv2.imread(imagePath)\n",
    "\timage = cv2.resize(image, (96, 96))\n",
    "\timage = img_to_array(image)\n",
    "\tdata.append(image)\n",
    "\t#Use os path sep to break apart image path into directories and separators, count back 2 to get the dog breed name\n",
    "\tlabel = imagePath.split(os.path.sep)[-2]\n",
    "    #store the dog breed name as the label\n",
    "\tlabels.append(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Train Test Split data\n",
    "1. Divide each data entry by 255 to scale integer values to float on a scale from 0-1, then create a numpy array\n",
    "2. Create numpy array for labels\n",
    "3. Binarize labels using binarizer alternative to one hot encoding\n",
    "4. Define X and Y train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the raw pixel intensities to the range [0, 1]\n",
    "data = np.array(data, dtype=\"float\") / 255.0\n",
    "labels = np.array(labels)\n",
    "\n",
    "# binarize the labels\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "\n",
    "# partition the data into training and testing splits using 80% of\n",
    "# the data for training and the remaining 20% for testing\n",
    "(X_train, X_test, y_train, y_test) = train_test_split(data,\n",
    "\tlabels, test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Info\n",
      "Training Data Shape: (559, 96, 96, 3)\n",
      "Training Data Labels Shape: (559, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Data Info\")\n",
    "print(\"Training Data Shape:\", X_train.shape)\n",
    "print(\"Training Data Labels Shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.64705882, 0.68627451, 0.7254902 ],\n",
       "        [0.65490196, 0.69411765, 0.73333333],\n",
       "        [0.65490196, 0.69411765, 0.73333333],\n",
       "        ...,\n",
       "        [0.68627451, 0.73333333, 0.78039216],\n",
       "        [0.68235294, 0.72941176, 0.77647059],\n",
       "        [0.68235294, 0.72941176, 0.77647059]],\n",
       "\n",
       "       [[0.63921569, 0.68627451, 0.7254902 ],\n",
       "        [0.64313725, 0.69019608, 0.72941176],\n",
       "        [0.6627451 , 0.70196078, 0.74117647],\n",
       "        ...,\n",
       "        [0.68627451, 0.73333333, 0.78039216],\n",
       "        [0.68627451, 0.73333333, 0.78039216],\n",
       "        [0.68627451, 0.73333333, 0.78039216]],\n",
       "\n",
       "       [[0.64313725, 0.69019608, 0.7372549 ],\n",
       "        [0.64705882, 0.69411765, 0.73333333],\n",
       "        [0.65882353, 0.70196078, 0.7372549 ],\n",
       "        ...,\n",
       "        [0.68627451, 0.73333333, 0.78039216],\n",
       "        [0.68627451, 0.73333333, 0.78039216],\n",
       "        [0.68627451, 0.73333333, 0.78039216]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.00784314, 0.00392157, 0.03921569],\n",
       "        [0.00392157, 0.00784314, 0.04705882],\n",
       "        [0.01176471, 0.01176471, 0.06666667],\n",
       "        ...,\n",
       "        [0.60784314, 0.6627451 , 0.70980392],\n",
       "        [0.58431373, 0.63921569, 0.68627451],\n",
       "        [0.56078431, 0.60784314, 0.65098039]],\n",
       "\n",
       "       [[0.00784314, 0.00392157, 0.04313725],\n",
       "        [0.        , 0.        , 0.04705882],\n",
       "        [0.00392157, 0.00392157, 0.05882353],\n",
       "        ...,\n",
       "        [0.60784314, 0.6627451 , 0.70980392],\n",
       "        [0.58823529, 0.64313725, 0.69019608],\n",
       "        [0.56078431, 0.60784314, 0.65098039]],\n",
       "\n",
       "       [[0.00784314, 0.        , 0.04705882],\n",
       "        [0.        , 0.        , 0.05490196],\n",
       "        [0.00392157, 0.00392157, 0.05882353],\n",
       "        ...,\n",
       "        [0.60392157, 0.65882353, 0.70588235],\n",
       "        [0.57647059, 0.63137255, 0.67843137],\n",
       "        [0.55686275, 0.60392157, 0.64313725]]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our image is an array of pixels ranging from 0 to 1 (Floats vs Integer)\n",
    "X_train[0, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       ...,\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our Training and Testing labels\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use image transformations and optimizer to train\n",
    "1. Keras Preprocessing image data generator to perform flips and rotations\n",
    "2. Use Adam optimizer to train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the image generator for data augmentation\n",
    "aug = ImageDataGenerator(rotation_range=25, width_shift_range=0.1,\n",
    "\theight_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
    "\thorizontal_flip=True, fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "----------- Compiling model: -----------\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# initialize the model\n",
    "print(\"----------------------------------------\")\n",
    "print(\"----------- Compiling Model: -----------\")\n",
    "print(\"----------------------------------------\")\n",
    "\n",
    "model = SmallerVGGNet.build(width=96, height=96, depth=3, classes=len(lb.classes_))\n",
    "optimize = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimize, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "--------------- Training ---------------\n",
      "----------------------------------------\n",
      "Epoch 1/20\n",
      "17/17 [==============================] - 37s 2s/step - loss: 2.0711 - acc: 0.5037 - val_loss: 2.9580 - val_acc: 0.5286\n",
      "Epoch 2/20\n",
      "17/17 [==============================] - 33s 2s/step - loss: 1.4767 - acc: 0.5093 - val_loss: 1.4057 - val_acc: 0.5286\n",
      "Epoch 3/20\n",
      "17/17 [==============================] - 39s 2s/step - loss: 1.1051 - acc: 0.6145 - val_loss: 1.0785 - val_acc: 0.5357\n",
      "Epoch 4/20\n",
      "17/17 [==============================] - 34s 2s/step - loss: 1.0453 - acc: 0.6054 - val_loss: 1.3797 - val_acc: 0.5929\n",
      "Epoch 5/20\n",
      "17/17 [==============================] - 34s 2s/step - loss: 0.9510 - acc: 0.6252 - val_loss: 1.2950 - val_acc: 0.6357\n",
      "Epoch 6/20\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.9098 - acc: 0.6420 - val_loss: 1.0225 - val_acc: 0.6786\n",
      "Epoch 7/20\n",
      "17/17 [==============================] - 35s 2s/step - loss: 0.9210 - acc: 0.6154 - val_loss: 1.1270 - val_acc: 0.6286\n",
      "Epoch 8/20\n",
      "17/17 [==============================] - 36s 2s/step - loss: 0.8106 - acc: 0.6694 - val_loss: 1.9795 - val_acc: 0.4071\n",
      "Epoch 9/20\n",
      "17/17 [==============================] - 35s 2s/step - loss: 0.7978 - acc: 0.6826 - val_loss: 1.3534 - val_acc: 0.6000\n",
      "Epoch 10/20\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.7981 - acc: 0.6956 - val_loss: 1.5321 - val_acc: 0.6143\n",
      "Epoch 11/20\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.8195 - acc: 0.6459 - val_loss: 1.5360 - val_acc: 0.6071\n",
      "Epoch 12/20\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.8305 - acc: 0.6918 - val_loss: 2.0492 - val_acc: 0.6000\n",
      "Epoch 13/20\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.7562 - acc: 0.6991 - val_loss: 1.2019 - val_acc: 0.6857\n",
      "Epoch 14/20\n",
      "17/17 [==============================] - 35s 2s/step - loss: 0.7838 - acc: 0.7046 - val_loss: 1.2004 - val_acc: 0.6071\n",
      "Epoch 15/20\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.7406 - acc: 0.7230 - val_loss: 1.3403 - val_acc: 0.5929\n",
      "Epoch 16/20\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.8392 - acc: 0.7360 - val_loss: 1.1904 - val_acc: 0.6214\n",
      "Epoch 17/20\n",
      "17/17 [==============================] - 34s 2s/step - loss: 0.7856 - acc: 0.7067 - val_loss: 1.1087 - val_acc: 0.6571\n",
      "Epoch 18/20\n",
      "17/17 [==============================] - 35s 2s/step - loss: 0.6875 - acc: 0.7416 - val_loss: 1.2750 - val_acc: 0.6500\n",
      "Epoch 19/20\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.6970 - acc: 0.7316 - val_loss: 1.0341 - val_acc: 0.6786\n",
      "Epoch 20/20\n",
      "17/17 [==============================] - 31s 2s/step - loss: 0.5721 - acc: 0.7880 - val_loss: 1.2406 - val_acc: 0.6286\n"
     ]
    }
   ],
   "source": [
    "# train the network\n",
    "print(\"----------------------------------------\")\n",
    "print(\"--------------- Training ---------------\")\n",
    "print(\"----------------------------------------\")\n",
    "H = model.fit_generator(\n",
    "\taug.flow(X_train, y_train, batch_size=BS),\n",
    "\tvalidation_data=(X_test, y_test),\n",
    "\tsteps_per_epoch=len(X_train) // BS,\n",
    "\tepochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save a model file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Please enter a name for the saved model:\n",
      "----------------------------------------\n",
      "jupyterModel\n"
     ]
    }
   ],
   "source": [
    "#Export a model file to be used later\n",
    "print(\"----------------------------------------\")\n",
    "print(\"Please enter a name for the saved model:\")\n",
    "print(\"----------------------------------------\")\n",
    "trainedModel = input()\n",
    "model.save(trainedModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save a label file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Please enter a name for the saved labels:\n",
      "----------------------------------------\n",
      "jupyterLabels\n"
     ]
    }
   ],
   "source": [
    "#Save the label file to be used later\n",
    "print(\"----------------------------------------\")\n",
    "print(\"Please enter a name for the saved labels:\")\n",
    "print(\"----------------------------------------\")\n",
    "labelFile = input()\n",
    "f = open(labelFile, \"wb\")\n",
    "f.write(pickle.dumps(lb))\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
